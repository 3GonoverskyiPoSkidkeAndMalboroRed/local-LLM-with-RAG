#!/usr/bin/env python3
"""
–°–∏—Å—Ç–µ–º–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏
–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å –º–∏–≥—Ä–∞—Ü–∏–∏ –∏ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
"""

import os
import sys
import json
import sqlite3
import hashlib
import asyncio
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime
from pathlib import Path
import logging
import statistics

# Add parent directory to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

logger = logging.getLogger(__name__)

class ValidationError(Exception):
    """Base exception for validation errors"""
    pass

class DataIntegrityValidator:
    """–í–∞–ª–∏–¥–∞—Ç–æ—Ä —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –º–∏–≥—Ä–∞—Ü–∏–∏"""
    
    def __init__(self, db_path: str):
        self.db_path = db_path
        self.validation_results = {}
        self.errors = []
        self.warnings = []
    
    def validate_database_structure(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("Validating database structure...")
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω—ã—Ö —Ç–∞–±–ª–∏—Ü
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
            tables = [row[0] for row in cursor.fetchall()]
            
            required_tables = ['documents', 'embeddings']
            missing_tables = [table for table in required_tables if table not in tables]
            
            if missing_tables:
                self.errors.append(f"Missing required tables: {missing_tables}")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã documents
            cursor.execute("PRAGMA table_info(documents)")
            doc_columns = [row[1] for row in cursor.fetchall()]
            
            required_doc_columns = ['id', 'content', 'metadata', 'source']
            missing_doc_columns = [col for col in required_doc_columns if col not in doc_columns]
            
            if missing_doc_columns:
                self.errors.append(f"Missing columns in documents table: {missing_doc_columns}")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Ç–∞–±–ª–∏—Ü—ã embeddings
            cursor.execute("PRAGMA table_info(embeddings)")
            emb_columns = [row[1] for row in cursor.fetchall()]
            
            required_emb_columns = ['document_id', 'embedding', 'provider', 'model']
            missing_emb_columns = [col for col in required_emb_columns if col not in emb_columns]
            
            if missing_emb_columns:
                self.errors.append(f"Missing columns in embeddings table: {missing_emb_columns}")
                return False
            
            conn.close()
            
            self.validation_results['database_structure'] = {
                'valid': True,
                'tables': tables,
                'document_columns': doc_columns,
                'embedding_columns': emb_columns
            }
            
            logger.info("‚úÖ Database structure validation passed")
            return True
            
        except Exception as e:
            self.errors.append(f"Database structure validation failed: {e}")
            logger.error(f"‚ùå Database structure validation failed: {e}")
            return False
    
    def validate_data_consistency(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö"""
        logger.info("Validating data consistency...")
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–º–µ—é—Ç –∫–æ–Ω—Ç–µ–Ω—Ç
            cursor.execute("SELECT COUNT(*) FROM documents WHERE content IS NULL OR content = ''")
            empty_content_count = cursor.fetchone()[0]
            
            if empty_content_count > 0:
                self.warnings.append(f"Found {empty_content_count} documents with empty content")
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≤—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å—Å—ã–ª–∞—é—Ç—Å—è –Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
            cursor.execute("""
                SELECT COUNT(*) FROM embeddings e
                LEFT JOIN documents d ON e.document_id = d.id
                WHERE d.id IS NULL
            """)
            orphaned_embeddings = cursor.fetchone()[0]
            
            if orphaned_embeddings > 0:
                self.errors.append(f"Found {orphaned_embeddings} orphaned embeddings")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≤—Å–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∏–º–µ—é—Ç –≤–∞–ª–∏–¥–Ω—ã–µ JSON –¥–∞–Ω–Ω—ã–µ
            cursor.execute("SELECT document_id, embedding FROM embeddings")
            invalid_embeddings = []
            
            for row in cursor.fetchall():
                doc_id, embedding_data = row
                try:
                    embedding = json.loads(embedding_data)
                    if not isinstance(embedding, list) or len(embedding) == 0:
                        invalid_embeddings.append(doc_id)
                except json.JSONDecodeError:
                    invalid_embeddings.append(doc_id)
            
            if invalid_embeddings:
                self.errors.append(f"Found {len(invalid_embeddings)} invalid embeddings for documents: {invalid_embeddings[:10]}")
                return False
            
            conn.close()
            
            self.validation_results['data_consistency'] = {
                'valid': True,
                'empty_content_documents': empty_content_count,
                'orphaned_embeddings': orphaned_embeddings,
                'invalid_embeddings': len(invalid_embeddings)
            }
            
            logger.info("‚úÖ Data consistency validation passed")
            return True
            
        except Exception as e:
            self.errors.append(f"Data consistency validation failed: {e}")
            logger.error(f"‚ùå Data consistency validation failed: {e}")
            return False
    
    def validate_yandex_embeddings(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å Yandex Cloud —ç–º–±–µ–¥–¥–∏–Ω–≥–∏"""
        logger.info("Validating Yandex Cloud embeddings...")
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤
            cursor.execute("SELECT COUNT(*) FROM documents")
            total_documents = cursor.fetchone()[0]
            
            # –ü–æ–¥—Å—á–∏—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã —Å Yandex —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
            cursor.execute("""
                SELECT COUNT(DISTINCT e.document_id) 
                FROM embeddings e 
                WHERE e.provider = 'yandex_cloud'
            """)
            yandex_embedded_docs = cursor.fetchone()[0]
            
            # –í—ã—á–∏—Å–ª–∏—Ç—å –ø–æ–∫—Ä—ã—Ç–∏–µ
            coverage_percentage = (yandex_embedded_docs / total_documents * 100) if total_documents > 0 else 0
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
            cursor.execute("""
                SELECT embedding FROM embeddings 
                WHERE provider = 'yandex_cloud' 
                LIMIT 100
            """)
            
            dimensions = []
            for row in cursor.fetchall():
                try:
                    embedding = json.loads(row[0])
                    dimensions.append(len(embedding))
                except json.JSONDecodeError:
                    continue
            
            # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
            unique_dimensions = set(dimensions)
            dimension_consistency = len(unique_dimensions) <= 1
            
            if not dimension_consistency:
                self.errors.append(f"Inconsistent embedding dimensions: {unique_dimensions}")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ (95%)
            min_coverage = 95.0
            if coverage_percentage < min_coverage:
                self.errors.append(f"Low Yandex embedding coverage: {coverage_percentage:.1f}% < {min_coverage}%")
                return False
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (–Ω–µ –≤—Å–µ –Ω—É–ª–∏)
            cursor.execute("""
                SELECT embedding FROM embeddings 
                WHERE provider = 'yandex_cloud' 
                LIMIT 10
            """)
            
            zero_embeddings = 0
            for row in cursor.fetchall():
                try:
                    embedding = json.loads(row[0])
                    if all(x == 0 for x in embedding):
                        zero_embeddings += 1
                except json.JSONDecodeError:
                    continue
            
            if zero_embeddings > 0:
                self.warnings.append(f"Found {zero_embeddings} zero embeddings")
            
            conn.close()
            
            self.validation_results['yandex_embeddings'] = {
                'valid': True,
                'total_documents': total_documents,
                'yandex_embedded_documents': yandex_embedded_docs,
                'coverage_percentage': coverage_percentage,
                'embedding_dimensions': list(unique_dimensions),
                'dimension_consistency': dimension_consistency,
                'zero_embeddings': zero_embeddings
            }
            
            logger.info(f"‚úÖ Yandex embeddings validation passed")
            logger.info(f"   Coverage: {coverage_percentage:.1f}%")
            logger.info(f"   Dimensions: {list(unique_dimensions)}")
            
            return True
            
        except Exception as e:
            self.errors.append(f"Yandex embeddings validation failed: {e}")
            logger.error(f"‚ùå Yandex embeddings validation failed: {e}")
            return False
    
    def validate_embedding_quality(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤"""
        logger.info("Validating embedding quality...")
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # –ü–æ–ª—É—á–∏—Ç—å –≤—ã–±–æ—Ä–∫—É —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            cursor.execute("""
                SELECT d.content, e.embedding 
                FROM documents d
                JOIN embeddings e ON d.id = e.document_id
                WHERE e.provider = 'yandex_cloud'
                ORDER BY RANDOM()
                LIMIT 50
            """)
            
            samples = cursor.fetchall()
            
            if len(samples) == 0:
                self.warnings.append("No Yandex embeddings found for quality validation")
                return True
            
            quality_metrics = {
                'sample_count': len(samples),
                'dimension_stats': {},
                'magnitude_stats': {},
                'similarity_stats': {}
            }
            
            embeddings_data = []
            magnitudes = []
            
            for content, embedding_json in samples:
                try:
                    embedding = json.loads(embedding_json)
                    embeddings_data.append((content, embedding))
                    
                    # –í—ã—á–∏—Å–ª–∏—Ç—å –º–∞–≥–Ω–∏—Ç—É–¥—É
                    magnitude = sum(x * x for x in embedding) ** 0.5
                    magnitudes.append(magnitude)
                    
                except json.JSONDecodeError:
                    continue
            
            if not magnitudes:
                self.errors.append("No valid embeddings found for quality analysis")
                return False
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–µ–π
            dimensions = [len(emb[1]) for emb in embeddings_data]
            quality_metrics['dimension_stats'] = {
                'min': min(dimensions),
                'max': max(dimensions),
                'mean': statistics.mean(dimensions),
                'unique_count': len(set(dimensions))
            }
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –º–∞–≥–Ω–∏—Ç—É–¥
            quality_metrics['magnitude_stats'] = {
                'min': min(magnitudes),
                'max': max(magnitudes),
                'mean': statistics.mean(magnitudes),
                'median': statistics.median(magnitudes),
                'std_dev': statistics.stdev(magnitudes) if len(magnitudes) > 1 else 0
            }
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ –∞–Ω–æ–º–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            mean_magnitude = quality_metrics['magnitude_stats']['mean']
            std_magnitude = quality_metrics['magnitude_stats']['std_dev']
            
            # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å –æ—á–µ–Ω—å –Ω–∏–∑–∫–æ–π –∏–ª–∏ –≤—ã—Å–æ–∫–æ–π –º–∞–≥–Ω–∏—Ç—É–¥–æ–π –º–æ–≥—É—Ç –±—ã—Ç—å –ø—Ä–æ–±–ª–µ–º–∞—Ç–∏—á–Ω—ã–º–∏
            anomalous_count = 0
            for mag in magnitudes:
                if abs(mag - mean_magnitude) > 3 * std_magnitude:
                    anomalous_count += 1
            
            if anomalous_count > len(magnitudes) * 0.1:  # –ë–æ–ª–µ–µ 10% –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö
                self.warnings.append(f"High number of anomalous embeddings: {anomalous_count}/{len(magnitudes)}")
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ –Ω—É–ª–µ–≤—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            zero_magnitude_count = sum(1 for mag in magnitudes if mag < 1e-10)
            if zero_magnitude_count > 0:
                self.warnings.append(f"Found {zero_magnitude_count} near-zero magnitude embeddings")
            
            conn.close()
            
            self.validation_results['embedding_quality'] = {
                'valid': True,
                'metrics': quality_metrics,
                'anomalous_embeddings': anomalous_count,
                'zero_magnitude_embeddings': zero_magnitude_count
            }
            
            logger.info("‚úÖ Embedding quality validation passed")
            logger.info(f"   Sample size: {len(samples)}")
            logger.info(f"   Mean magnitude: {mean_magnitude:.4f}")
            logger.info(f"   Anomalous embeddings: {anomalous_count}")
            
            return True
            
        except Exception as e:
            self.errors.append(f"Embedding quality validation failed: {e}")
            logger.error(f"‚ùå Embedding quality validation failed: {e}")
            return False
    
    def validate_migration_completeness(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –ø–æ–ª–Ω–æ—Ç—É –º–∏–≥—Ä–∞—Ü–∏–∏"""
        logger.info("Validating migration completeness...")
        
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–º–µ—é—Ç —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —ç–º–±–µ–¥–¥–∏–Ω–≥
            cursor.execute("""
                SELECT COUNT(*) FROM documents d
                LEFT JOIN embeddings e ON d.id = e.document_id
                WHERE e.document_id IS NULL
            """)
            documents_without_embeddings = cursor.fetchone()[0]
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≤—Å–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–º–µ—é—Ç Yandex —ç–º–±–µ–¥–¥–∏–Ω–≥
            cursor.execute("""
                SELECT COUNT(*) FROM documents d
                LEFT JOIN embeddings e ON d.id = e.document_id AND e.provider = 'yandex_cloud'
                WHERE e.document_id IS NULL
            """)
            documents_without_yandex = cursor.fetchone()[0]
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            cursor.execute("""
                SELECT document_id, provider, model, COUNT(*) as count
                FROM embeddings
                GROUP BY document_id, provider, model
                HAVING COUNT(*) > 1
            """)
            duplicate_embeddings = cursor.fetchall()
            
            # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å—Ç–∞—Ä—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã
            cursor.execute("""
                SELECT DISTINCT provider FROM embeddings
                WHERE provider != 'yandex_cloud'
            """)
            old_providers = [row[0] for row in cursor.fetchall()]
            
            conn.close()
            
            # –û—Ü–µ–Ω–∫–∞ –ø–æ–ª–Ω–æ—Ç—ã –º–∏–≥—Ä–∞—Ü–∏–∏
            migration_complete = (
                documents_without_yandex == 0 and
                len(duplicate_embeddings) == 0
            )
            
            if documents_without_embeddings > 0:
                self.warnings.append(f"Found {documents_without_embeddings} documents without any embeddings")
            
            if documents_without_yandex > 0:
                self.errors.append(f"Found {documents_without_yandex} documents without Yandex embeddings")
            
            if duplicate_embeddings:
                self.warnings.append(f"Found {len(duplicate_embeddings)} duplicate embedding entries")
            
            if old_providers:
                self.warnings.append(f"Old embedding providers still present: {old_providers}")
            
            self.validation_results['migration_completeness'] = {
                'valid': migration_complete,
                'documents_without_embeddings': documents_without_embeddings,
                'documents_without_yandex': documents_without_yandex,
                'duplicate_embeddings': len(duplicate_embeddings),
                'old_providers': old_providers,
                'migration_complete': migration_complete
            }
            
            if migration_complete:
                logger.info("‚úÖ Migration completeness validation passed")
            else:
                logger.warning("‚ö†Ô∏è  Migration completeness validation has issues")
            
            return migration_complete
            
        except Exception as e:
            self.errors.append(f"Migration completeness validation failed: {e}")
            logger.error(f"‚ùå Migration completeness validation failed: {e}")
            return False
    
    def run_full_validation(self) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å—Ç–∏—Ç—å –ø–æ–ª–Ω—É—é –≤–∞–ª–∏–¥–∞—Ü–∏—é"""
        logger.info("Starting full validation...")
        
        validation_start = datetime.now()
        
        # –ó–∞–ø—É—Å—Ç–∏—Ç—å –≤—Å–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
        validations = [
            ('database_structure', self.validate_database_structure),
            ('data_consistency', self.validate_data_consistency),
            ('yandex_embeddings', self.validate_yandex_embeddings),
            ('embedding_quality', self.validate_embedding_quality),
            ('migration_completeness', self.validate_migration_completeness)
        ]
        
        passed_validations = 0
        total_validations = len(validations)
        
        for validation_name, validation_func in validations:
            try:
                result = validation_func()
                if result:
                    passed_validations += 1
                    logger.info(f"‚úÖ {validation_name} validation passed")
                else:
                    logger.error(f"‚ùå {validation_name} validation failed")
            except Exception as e:
                logger.error(f"‚ùå {validation_name} validation error: {e}")
                self.errors.append(f"{validation_name} validation error: {e}")
        
        validation_end = datetime.now()
        
        # –°–æ–∑–¥–∞—Ç—å –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        validation_report = {
            'validation_id': validation_start.strftime("%Y%m%d_%H%M%S"),
            'database_path': self.db_path,
            'validation_start': validation_start.isoformat(),
            'validation_end': validation_end.isoformat(),
            'duration_seconds': (validation_end - validation_start).total_seconds(),
            'total_validations': total_validations,
            'passed_validations': passed_validations,
            'failed_validations': total_validations - passed_validations,
            'success_rate': (passed_validations / total_validations) * 100,
            'overall_valid': passed_validations == total_validations,
            'validation_results': self.validation_results,
            'errors': self.errors,
            'warnings': self.warnings
        }
        
        # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∏—Ç–æ–≥–æ–≤
        logger.info(f"\n{'='*60}")
        logger.info("VALIDATION SUMMARY")
        logger.info('='*60)
        logger.info(f"Database: {self.db_path}")
        logger.info(f"Duration: {validation_report['duration_seconds']:.2f}s")
        logger.info(f"Validations: {passed_validations}/{total_validations} passed")
        logger.info(f"Success rate: {validation_report['success_rate']:.1f}%")
        
        if validation_report['overall_valid']:
            logger.info("üéâ ALL VALIDATIONS PASSED!")
        else:
            logger.error("‚ö†Ô∏è  SOME VALIDATIONS FAILED")
        
        if self.errors:
            logger.error(f"\nErrors ({len(self.errors)}):")
            for error in self.errors:
                logger.error(f"  ‚Ä¢ {error}")
        
        if self.warnings:
            logger.warning(f"\nWarnings ({len(self.warnings)}):")
            for warning in self.warnings:
                logger.warning(f"  ‚Ä¢ {warning}")
        
        return validation_report
    
    def save_validation_report(self, report: Dict[str, Any], output_file: str = None) -> str:
        """–°–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ—Ç—á–µ—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏"""
        if output_file is None:
            output_file = f"validation_report_{report['validation_id']}.json"
        
        try:
            with open(output_file, 'w') as f:
                json.dump(report, f, indent=2, default=str)
            
            logger.info(f"Validation report saved: {output_file}")
            return output_file
            
        except Exception as e:
            logger.error(f"Failed to save validation report: {e}")
            return None

def main():
    """Main validation script"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Validate database migration")
    parser.add_argument(
        '--database',
        default='files/vector_db.sqlite',
        help='Path to the database file'
    )
    parser.add_argument(
        '--output',
        help='Output file for validation report'
    )
    parser.add_argument(
        '--validation',
        choices=['structure', 'consistency', 'yandex', 'quality', 'completeness', 'all'],
        default='all',
        help='Specific validation to run'
    )
    
    args = parser.parse_args()
    
    # Setup logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    validator = DataIntegrityValidator(args.database)
    
    try:
        if args.validation == 'all':
            report = validator.run_full_validation()
        else:
            # Run specific validation
            validation_methods = {
                'structure': validator.validate_database_structure,
                'consistency': validator.validate_data_consistency,
                'yandex': validator.validate_yandex_embeddings,
                'quality': validator.validate_embedding_quality,
                'completeness': validator.validate_migration_completeness
            }
            
            method = validation_methods[args.validation]
            result = method()
            
            report = {
                'validation_type': args.validation,
                'result': result,
                'validation_results': validator.validation_results,
                'errors': validator.errors,
                'warnings': validator.warnings
            }
        
        # Save report
        if args.output:
            validator.save_validation_report(report, args.output)
        else:
            validator.save_validation_report(report)
        
        # Return appropriate exit code
        if report.get('overall_valid', result if 'result' in report else False):
            return 0
        else:
            return 1
            
    except Exception as e:
        logger.error(f"Validation failed with error: {e}")
        return 1

if __name__ == "__main__":
    import sys
    sys.exit(main())