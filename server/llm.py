from operator import itemgetter
import asyncio
import concurrent.futures
import os
from typing import Dict, Any

from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler
from langchain.memory import ConversationBufferMemory
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from langchain_core.messages import get_buffer_string
from langchain_core.prompts import format_document
from langchain.prompts.prompt import PromptTemplate


condense_question = """–ó–∞–¥–∞—á–∞: –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, —Å–¥–µ–ª–∞–≤ –µ–≥–æ —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–º –∏ –ø–æ–Ω—è—Ç–Ω—ã–º –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞.

### –ò—Å—Ç–æ—Ä–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä–∞:
{chat_history}

### –ù–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
{question}

### –ü–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å:
–ò—Å—Ö–æ–¥—è –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –±–µ—Å–µ–¥—ã, –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç:"""
CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(condense_question)

answer = """
### –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:
–¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è–º –Ω–∞–π—Ç–∏ —Ç–æ—á–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö.

### –ü—Ä–∞–≤–∏–ª–∞ —Ä–∞–±–æ—Ç—ã:
1. –í–°–ï–ì–î–ê —Å–Ω–∞—á–∞–ª–∞ –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –∏–∑—É—á–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
2. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –µ—Å—Ç—å –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –¢–û–õ–¨–ö–û –µ—ë –¥–ª—è –æ—Ç–≤–µ—Ç–∞
3. –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç –≤ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ö ‚Äî —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏ –æ–± —ç—Ç–æ–º
4. –î–∞–≤–∞–π –ø–æ–¥—Ä–æ–±–Ω—ã–µ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã
5. –ü—Ä–∏ —Ü–∏—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏ —É–∫–∞–∑—ã–≤–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫ –¥–æ–∫—É–º–µ–Ω—Ç–∞

### –ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:
{context}

### –í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:
{question}

### –û—Ç–≤–µ—Ç:
–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–≤ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:"""
ANSWER_PROMPT = ChatPromptTemplate.from_template(answer)

DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(
    template="üìÑ –ò—Å—Ç–æ—á–Ω–∏–∫: {source} (—Å—Ç—Ä–∞–Ω–∏—Ü–∞ {page})\nüìù –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:\n{page_content}\n"
)

# –°–æ–∑–¥–∞–µ–º –æ–±—â–∏–π –ø—É–ª –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è CPU-bound –æ–ø–µ—Ä–∞—Ü–∏–π
_thread_pool = concurrent.futures.ThreadPoolExecutor(max_workers=10)


def _combine_documents(
    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator="\n" + "="*50 + "\n"
):
    """–£–ª—É—á—à–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Å –ª—É—á—à–∏–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    if not docs:
        return "–î–æ–∫—É–º–µ–Ω—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã."
    
    doc_strings = []
    for i, doc in enumerate(docs, 1):
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            source = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫"
            page = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"
            
            if hasattr(doc, 'metadata') and doc.metadata:
                source = doc.metadata.get('source', source)
                page = doc.metadata.get('page', page)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ –ø—É—Ç–∏ –¥–ª—è –∫—Ä–∞—Å–∏–≤–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            filename = os.path.basename(source) if source != "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫" else f"–î–æ–∫—É–º–µ–Ω—Ç {i}"
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º —Ñ–∞–π–ª–∞ –≤–º–µ—Å—Ç–æ –Ω–æ–º–µ—Ä–∞
            content = f"üìÑ {filename}\n"
            content += f"üìÅ –ü—É—Ç—å: {source}\n"
            content += f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞: {page}\n"
            content += f"üìù –°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ:\n{doc.page_content}\n"
            
            doc_strings.append(content)
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞ {i}: {e}")
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ –≤ –æ—à–∏–±–∫–µ, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ
            try:
                filename = os.path.basename(source) if 'source' in locals() and source != "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫" else f"–î–æ–∫—É–º–µ–Ω—Ç {i}"
            except:
                filename = f"–î–æ–∫—É–º–µ–Ω—Ç {i}"
            doc_strings.append(f"üìÑ {filename}: –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
    
    result = document_separator.join(doc_strings)
    print(f"–û–±—ä–µ–¥–∏–Ω–µ–Ω–æ {len(doc_strings)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ä–∞–∑–º–µ—Ä–æ–º {len(result)} —Å–∏–º–≤–æ–ª–æ–≤")
    return result


def _sync_chat_invoke(final_chain, inputs):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ü–µ–ø–æ—á–∫–∏ LLM"""
    return final_chain.invoke(inputs)


async def _async_chat_invoke(final_chain, inputs, timeout: int = 100):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –æ–±–µ—Ä—Ç–∫–∞ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è LLM —Ü–µ–ø–æ—á–∫–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ —Å —Ç–∞–π–º-–∞—É—Ç–æ–º"""
    try:
        loop = asyncio.get_running_loop()
    except RuntimeError:
        # –ï—Å–ª–∏ –Ω–µ—Ç –∑–∞–ø—É—â–µ–Ω–Ω–æ–≥–æ event loop, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
    
    try:
        return await asyncio.wait_for(
            loop.run_in_executor(_thread_pool, _sync_chat_invoke, final_chain, inputs),
            timeout=timeout
        )
    except asyncio.TimeoutError:
        raise TimeoutError(f"–ü—Ä–µ–≤—ã—à–µ–Ω —Ç–∞–π–º–∞—É—Ç {timeout} —Å–µ–∫—É–Ω–¥ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ LLM –∑–∞–ø—Ä–æ—Å–∞")
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ _async_chat_invoke: {e}")
        raise


def getStreamingChain(question: str, memory, llm, db):
    retriever = db.as_retriever(search_kwargs={"k": 10})
    loaded_memory = RunnablePassthrough.assign(
        chat_history=RunnableLambda(
            lambda x: "\n".join(
                [f"{item['role']}: {item['content']}" for item in x["memory"]]
            )
        ),
    )

    standalone_question = {
        "standalone_question": {
            "question": lambda x: x["question"],
            "chat_history": lambda x: x["chat_history"],
        }
        | CONDENSE_QUESTION_PROMPT
        | llm
        | (lambda x: x.content if hasattr(x, "content") else x)
    }

    retrieved_documents = {
        "docs": itemgetter("standalone_question") | retriever,
        "question": lambda x: x["standalone_question"],
    }

    final_inputs = {
        "context": lambda x: _combine_documents(x["docs"]),
        "question": itemgetter("question"),
    }

    answer = final_inputs | ANSWER_PROMPT | llm

    final_chain = loaded_memory | standalone_question | retrieved_documents | answer

    return final_chain.stream({"question": question, "memory": memory})


def getChatChain(llm, db):
    """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
    # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ retriever –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ RAG
    retriever = db.as_retriever(
        search_type="similarity",
        search_kwargs={
            "k": 6,  # –£—Å–∫–æ—Ä–µ–Ω–∏–µ: –º–µ–Ω—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ = –±—ã—Å—Ç—Ä–µ–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        }
    )

    def chat(question: str):
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        memory = ConversationBufferMemory(return_messages=True, output_key="answer", input_key="question")
        
        loaded_memory = RunnablePassthrough.assign(
            chat_history=RunnableLambda(memory.load_memory_variables)
            | itemgetter("history"),
        )

        standalone_question = {
            "standalone_question": {
                "question": lambda x: x["question"],
                "chat_history": lambda x: get_buffer_string(x["chat_history"]),
            }
            | CONDENSE_QUESTION_PROMPT
            | llm
            | (lambda x: x.content if hasattr(x, "content") else x)
        }

        # –¢–µ–ø–µ—Ä—å –º—ã –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        retrieved_documents = {
            "docs": itemgetter("standalone_question") | retriever,
            "question": lambda x: x["standalone_question"],
        }

        # –¢–µ–ø–µ—Ä—å –º—ã —Å—Ç—Ä–æ–∏–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        final_inputs = {
            "context": lambda x: _combine_documents(x["docs"]),
            "question": itemgetter("question"),
        }

        # –ò, –Ω–∞–∫–æ–Ω–µ—Ü, –º—ã –¥–µ–ª–∞–µ–º —á–∞—Å—Ç—å, –∫–æ—Ç–æ—Ä–∞—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç—ã
        answer = {
            "answer": final_inputs
            | ANSWER_PROMPT
            | llm.with_config(callbacks=[StreamingStdOutCallbackHandler()]),
            "docs": itemgetter("docs"),
        }

        final_chain = loaded_memory | standalone_question | retrieved_documents | answer

        try:
            print(f"getChatChain: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–∞: {question}")
            inputs = {"question": question}
            result = final_chain.invoke(inputs)
            
            if "answer" not in result:
                print("getChatChain: –∫–ª—é—á 'answer' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ")
                return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏"
                
            answer_content = result["answer"].content if hasattr(result["answer"], "content") else result["answer"]
            memory.save_context(inputs, {"answer": answer_content})
            
            print(f"getChatChain: —É—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç: {answer_content[:100]}...")
            return answer_content
        except Exception as e:
            import traceback
            print(f"getChatChain: –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞: {str(e)}")
            print(traceback.format_exc())
            return f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}"

    return chat


def getAsyncChatChain(llm, db):
    """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π Yandex Cloud"""
    # –£–ª—É—á—à–µ–Ω–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ retriever –¥–ª—è –ª—É—á—à–µ–≥–æ –∫–∞—á–µ—Å—Ç–≤–∞ RAG
    retriever = db.as_retriever(
        search_type="similarity",
        search_kwargs={
            "k": 6,  # –£—Å–∫–æ—Ä–µ–Ω–∏–µ: –º–µ–Ω—å—à–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ = –±—ã—Å—Ç—Ä–µ–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
        }
    )

    async def async_chat(question: str) -> Dict[str, Any]:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        memory = ConversationBufferMemory(return_messages=True, output_key="answer", input_key="question")
        
        loaded_memory = RunnablePassthrough.assign(
            chat_history=RunnableLambda(memory.load_memory_variables)
            | itemgetter("history"),
        )

        standalone_question = {
            "standalone_question": {
                "question": lambda x: x["question"],
                "chat_history": lambda x: get_buffer_string(x["chat_history"]),
            }
            | CONDENSE_QUESTION_PROMPT
            | llm
            | (lambda x: x.content if hasattr(x, "content") else x)
        }

        # –¢–µ–ø–µ—Ä—å –º—ã –∏–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã
        retrieved_documents = {
            "docs": itemgetter("standalone_question") | retriever,
            "question": lambda x: x["standalone_question"],
        }

        # –¢–µ–ø–µ—Ä—å –º—ã —Å—Ç—Ä–æ–∏–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
        final_inputs = {
            "context": lambda x: _combine_documents(x["docs"]),
            "question": itemgetter("question"),
        }

        # –ò, –Ω–∞–∫–æ–Ω–µ—Ü, –º—ã –¥–µ–ª–∞–µ–º —á–∞—Å—Ç—å, –∫–æ—Ç–æ—Ä–∞—è –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—Ç–≤–µ—Ç—ã
        answer = {
            "answer": final_inputs
            | ANSWER_PROMPT
            | llm,  # –£–±–∏—Ä–∞–µ–º StreamingStdOutCallbackHandler –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–∏
            "docs": itemgetter("docs"),
        }

        final_chain = loaded_memory | standalone_question | retrieved_documents | answer

        try:
            print(f"getAsyncChatChain: –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–æ–ø—Ä–æ—Å–∞: {question}")
            inputs = {"question": question}
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø LLM –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å–ø–æ—Å–æ–±–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
            from config_utils import get_env_bool
            use_yandex_cloud = get_env_bool("USE_YANDEX_CLOUD", False)
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ª–∏ Yandex Cloud LLM
            is_yandex_llm = (
                use_yandex_cloud and 
                hasattr(llm, '_llm_type') and 
                'yandex' in str(llm._llm_type).lower()
            ) or (
                hasattr(llm, '__class__') and 
                'yandex' in str(llm.__class__.__name__).lower()
            )
            
            if is_yandex_llm:
                print(f"getAsyncChatChain: –ò—Å–ø–æ–ª—å–∑—É–µ–º Yandex Cloud LLM")
                
                try:
                    # –î–ª—è Yandex Cloud LLM –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä—è–º–æ–π –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –≤—ã–∑–æ–≤
                    result = await _async_chat_invoke(final_chain, inputs, timeout=120)  # –£–≤–µ–ª–∏—á–µ–Ω–Ω—ã–π —Ç–∞–π–º–∞—É—Ç –¥–ª—è Yandex Cloud
                    
                except Exception as yandex_error:
                    print(f"getAsyncChatChain: –û—à–∏–±–∫–∞ Yandex Cloud LLM: {yandex_error}")
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–∫–ª—é—á–µ–Ω –ª–∏ fallback
                    fallback_enabled = get_env_bool("YANDEX_FALLBACK_TO_OLLAMA", True)
                    
                    if fallback_enabled:
                        print(f"getAsyncChatChain: –ü–æ–ø—ã—Ç–∫–∞ fallback –Ω–∞ Ollama")
                        
                        # –°–æ–∑–¥–∞–µ–º fallback Ollama LLM
                        try:
                            from langchain_ollama import ChatOllama
                            ollama_host = os.environ.get("OLLAMA_HOST", "http://localhost:11434")
                            
                            fallback_llm = ChatOllama(
                                model="gemma3",  # –î–µ—Ñ–æ–ª—Ç–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è fallback
                                base_url=ollama_host,
                                temperature=0.1,
                                num_predict=200
                            )
                            
                            # –ü–µ—Ä–µ—Å–æ–∑–¥–∞–µ–º —Ü–µ–ø–æ—á–∫—É —Å fallback LLM
                            fallback_standalone_question = {
                                "standalone_question": {
                                    "question": lambda x: x["question"],
                                    "chat_history": lambda x: get_buffer_string(x["chat_history"]),
                                }
                                | CONDENSE_QUESTION_PROMPT
                                | fallback_llm
                                | (lambda x: x.content if hasattr(x, "content") else x)
                            }
                            
                            fallback_answer = {
                                "answer": final_inputs
                                | ANSWER_PROMPT
                                | fallback_llm,
                                "docs": itemgetter("docs"),
                            }
                            
                            fallback_chain = loaded_memory | fallback_standalone_question | retrieved_documents | fallback_answer
                            
                            print(f"getAsyncChatChain: –í—ã–ø–æ–ª–Ω—è–µ–º fallback –Ω–∞ Ollama")
                            result = await _async_chat_invoke(fallback_chain, inputs, timeout=100)
                            
                        except Exception as fallback_error:
                            print(f"getAsyncChatChain: –û—à–∏–±–∫–∞ fallback: {fallback_error}")
                            raise yandex_error  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –æ—à–∏–±–∫—É Yandex
                    else:
                        raise yandex_error
            else:
                print(f"getAsyncChatChain: –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é LLM (Ollama)")
                # –í—ã–ø–æ–ª–Ω—è–µ–º LLM —Ü–µ–ø–æ—á–∫—É –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ —Å —Ç–∞–π–º-–∞—É—Ç–æ–º
                result = await _async_chat_invoke(final_chain, inputs, timeout=100)
            
            if "answer" not in result:
                print("getAsyncChatChain: –∫–ª—é—á 'answer' –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ")
                return {
                    "answer": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏",
                    "docs": [],
                    "success": False
                }
                
            answer_content = result["answer"].content if hasattr(result["answer"], "content") else result["answer"]
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –ø–∞–º—è—Ç—å (—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ)
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(_thread_pool, memory.save_context, inputs, {"answer": answer_content})
            
            print(f"getAsyncChatChain: —É—Å–ø–µ—à–Ω—ã–π –æ—Ç–≤–µ—Ç: {answer_content[:100]}...")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            docs = result.get("docs", [])
            doc_contents = []
            doc_sources = []
            
            for doc in docs:
                if hasattr(doc, 'page_content'):
                    doc_contents.append(doc.page_content)
                if hasattr(doc, 'metadata') and doc.metadata.get('source'):
                    doc_sources.append(doc.metadata['source'])
            
            return {
                "answer": answer_content,
                "chunks": doc_contents,
                "files": list(set(doc_sources)),  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
                "success": True
            }
            
        except Exception as e:
            import traceback
            print(f"getAsyncChatChain: –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–∞: {str(e)}")
            print(traceback.format_exc())
            
            # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ Yandex Cloud
            error_message = f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∑–∞–ø—Ä–æ—Å–∞: {str(e)}"
            if "yandex" in str(e).lower() or "api" in str(e).lower():
                error_message = f"–û—à–∏–±–∫–∞ Yandex Cloud API: {str(e)}"
            
            return {
                "answer": error_message,
                "chunks": [],
                "files": [],
                "success": False
            }

    return async_chat
