# README

<p align="center">
    <img src="images/image.png" alt="Скриншот веб-интерфейса Streamlit" width="600">
</p>

## Требования

- [Ollama](https://ollama.ai/) версия 0.5.7 или выше.

## Установка

1. Клонируйте этот репозиторий на свой локальный компьютер.
2. Установите UV, следуя инструкциям на сайте Astral, [Установка](https://docs.astral.sh/uv/#installation).
3. Создайте виртуальное окружение и установите необходимые пакеты Python, выполнив команду `uv sync`.

## Запуск проекта

**Примечание:** В первый раз, когда вы запустите проект, он загрузит необходимые модели из Ollama для LLM и встраиваний. Это одноразовый процесс настройки и может занять некоторое время в зависимости от вашего интернет-соединения.

1. Запустите основной скрипт с помощью `uv app.py -m <model_name> -p <path_to_documents>`, чтобы указать модель и путь к документам. Если модель не указана, по умолчанию используется [mistral](https://ollama.com/library/mistral). Если путь не указан, по умолчанию используется `Research`, расположенный в репозитории в качестве примера.
2. При желании вы можете указать модель встраивания, которую хотите использовать, с помощью `-e <embedding_model_name>`. Если не указано, по умолчанию используется [nomic-embed-text](https://ollama.com/library/nomic-embed-text).

Это загрузит PDF и Markdown файлы, сгенерирует встраивания, выполнит запрос к коллекции и ответит на вопрос, определенный в `app.py`.

## Запуск интерфейса Streamlit

Запустите приложение Streamlit, выполнив команду `uv streamlit run ui.py` в вашем терминале.

Это запустит локальный веб-сервер и откроет новую вкладку в вашем браузере по умолчанию, где вы сможете взаимодействовать с приложением. Интерфейс Streamlit позволяет вам выбирать модели, выбирать папку, предоставляя более простой и интуитивно понятный способ взаимодействия с системой RAG чат-бота по сравнению с интерфейсом командной строки. Приложение будет обрабатывать загрузку документов, генерацию встраиваний, выполнение запросов к коллекции и отображение результатов интерактивно.

## Используемые технологии

- [Langchain](https://github.com/langchain/langchain): Библиотека Python для работы с большими языковыми моделями.
- [Ollama](https://ollama.ai/): Платформа для запуска больших языковых моделей локально.
- [Chroma](https://docs.trychroma.com/): Векторная база данных для хранения и извлечения встраиваний.
- [PyPDF](https://pypi.org/project/PyPDF2/): Библиотека Python для чтения и манипуляции PDF файлами.
- [Streamlit](https://streamlit.io/): Веб-фреймворк для создания интерактивных приложений для проектов в области машинного обучения и науки о данных.
- [UV](https://astral.sh/uv): Быстрый и эффективный установщик и резольвер пакетов Python.

## Запуск сервера

Для запуска сервера выполните команду:
